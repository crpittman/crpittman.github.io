[{"authors":["admin"],"categories":null,"content":"I am an AI Engineer currently employed by Soar Technology in Orlando, FL. I completed my PhD in May 2021 at the University of Central Florida in Orlando, FL under the supervision of Joseph J. LaViola. My research interests are broadly encapsulated in Human-Computer Interaction, specifically including augmented reality, novel input techniques, and pattern recognition. I remain a part-time member of the Interactive Systems \u0026amp; User Experiences Lab. My dissertation topic was \u0026ldquo;Evaluating Augmented Reality Tools for Physics Education.\u0026rdquo;\nOutside of my research, I am an avid fitness junky. My main focuses are bouldering and distance running, with cycling and yoga helping to round everything off.\n","date":1611100800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1611100800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://crpittman.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am an AI Engineer currently employed by Soar Technology in Orlando, FL. I completed my PhD in May 2021 at the University of Central Florida in Orlando, FL under the supervision of Joseph J.","tags":null,"title":"Corey Pittman","type":"authors"},{"authors":["Eugene M Taranta II","Corey Pittman","Mehran Maghoumi","Mykola Maslych","Yasmine M Moolenaar","Joseph J Laviola Jr"],"categories":null,"content":"","date":1611100800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1611100800,"objectID":"11b2b2e198032fbbc80afb52c0102bce","permalink":"https://crpittman.github.io/publication/machete/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/machete/","section":"publication","summary":"We present Machete, a straightforward segmenter one can use to isolate custom gestures in continuous input.","tags":["Gesture Recognition"],"title":"Machete: Easy, Efficient, and Precise Continuous Custom Gesture Segmentation","type":"publication"},{"authors":["Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1589155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589155200,"objectID":"8eccfb9d3624c056259f92c50b4c76bc","permalink":"https://crpittman.github.io/publication/phyar/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/phyar/","section":"publication","summary":"In this paper, we present a qualitative analysis of a prototype augmented reality application for the Microsoft Hololens with a focus on physics education.","tags":["Augmented Reality","Physics Education"],"title":"PhyAR: Determining the Utility of Augmented Reality for Physics Education in the Classroom","type":"publication"},{"authors":["Eugene M Taranta II","Corey Pittman","Jack P Oakley","Mykola Maslych","Mehran Maghoumi","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1587427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587427200,"objectID":"049c98c74d9a16377b38a011db1e645e","permalink":"https://crpittman.github.io/publication/2d-data-collection/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/2d-data-collection/","section":"publication","summary":"Those who design gesture recognizers and user interfaces often use data collection applications that enable users to comfortably produce gesture training samples. In contrast, games present unique contexts that impact cognitive load and have the potential to elicit rapid gesticulations as players react to dynamic conditions, which can result in high gesture form variability. However, the extent to which these gestures differ is presently unknown. To this end, we developed two games with unique mechanics, Follow the Leader (FTL) and Sleepy Town, as well as a standard data collection application. We collected gesture samples from 18 participants across all conditions for gestures of varying complexity, and through an analysis using relative, global, and distribution coverage measures, we confirm significant differences between conditions. We discuss the implications of our findings, and show that our FTL design is closer to being an ecologically valid data collection protocol with low implementation complexity.","tags":["Gesture Recognition","User Experience"],"title":"Moving Toward an Ecologically Valid Data Collection Protocol for 2D Gestures In Video Games","type":"publication"},{"authors":["Jihye Song","Olivia B. Newton","Stephen M. Fiore","Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1574208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574208000,"objectID":"5b15046c3a47a69cd3fda7af089aa32b","permalink":"https://crpittman.github.io/publication/onr3/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/onr3/","section":"publication","summary":"Building on recent work, we investigated the effect of training comprehension on performance across varying representations of uncertainty and varying degrees of visualization interactivity using a simulated course of action selection task.","tags":["Data Visualization"],"title":"Examining Training Comprehension and External Cognition in Evaluations of Uncertainty Visualizations to Support Decision Making","type":"publication"},{"authors":["Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1553299200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553299200,"objectID":"e2bf5f732424655b20b98dba110d52d1","permalink":"https://crpittman.github.io/publication/holophysics/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/holophysics/","section":"publication","summary":"We present the results of a series of interviews with secondary school teachers about their experience with AR and the features which would be most beneficial to them from a pedagogical perspective.","tags":["Augmented Reality"],"title":"Determining Design Requirements for AR Physics Education Applications","type":"publication"},{"authors":["Jihye Song","Olivia B. Newton","Stephen M. Fiore","Jonatham Coad","Jared Clark","Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1537488000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537488000,"objectID":"6eb8e129f589a7c74a09c503c4472e53","permalink":"https://crpittman.github.io/publication/onr2/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/onr2/","section":"publication","summary":"We evaluated how variations in training, coupled with assessments of knowledge acquisition and application, can inform uncertainty visualization research.","tags":["Data Visualization"],"title":"Examining the Impact of Training and Feedback on Visualization-Supported Decision Making under Uncertainty","type":"publication"},{"authors":["Stephen M. Fiore","Jihye Song","Olivia B. Newton","Corey Pittman","Samantha F. Warta","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1532131200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1532131200,"objectID":"4a256633aefbf45068fe480979cef34a","permalink":"https://crpittman.github.io/publication/onr1/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/onr1/","section":"publication","summary":"We evaluated how variations in training, coupled with assessments of knowledge acquisition and application, can inform uncertainty visualization research.","tags":["Data Visualization"],"title":"Determining the effect of training on uncertainty visualization evaluations","type":"publication"},{"authors":["Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1494806400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1494806400,"objectID":"2ab35d975f6cb66d73d23d9a57eb9a6c","permalink":"https://crpittman.github.io/publication/multiwave-gi/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/multiwave-gi/","section":"publication","summary":"We built an acoustic, gesture-based recognition system called Multiwave, which leverages the Doppler Effect to translate multidimensional movements into user interface commands.","tags":["Gesture Recognition","Novel User Interfaces"],"title":"Multiwave: Complex Hand Gesture Recognition Using the Doppler Effect","type":"publication"},{"authors":["Eugene M Taranta II","Amirreza Samiei","Mehran Maghoumi","Pooya Khaloo","Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1493942400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1493942400,"objectID":"6122ca0c13000e412cd5d2795ea8efbc","permalink":"https://crpittman.github.io/publication/jackknife/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/jackknife/","section":"publication","summary":"Our dynamic time warping based approach for both segmented and continuous data is designed to be a robust, go-to method for gesture recognition across a variety of modalities using only limited training samples.","tags":["Gesture Recognition"],"title":"Jackknife: A Reliable Reliable with Few Samples and Many Modalities","type":"publication"},{"authors":["Eugene M. Taranta II","Mehran Maghoumi","Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1476576000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1476576000,"objectID":"c2c28d9fc6344a7cba3de04cc341cad0","permalink":"https://crpittman.github.io/publication/sdg/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/sdg/","section":"publication","summary":"We introduce a novel technique called gesture path stochastic resampling (GPSR) that is computationally efficient, has minimal coding overhead, and yet despite its simplicity is able to achieve higher accuracy than competitive, state-of-the-art approaches.","tags":["Gesture Recognition"],"title":"A Rapid Prototyping Approach to Synthetic Data Generation for Improved 2D Gesture Recognition","type":"publication"},{"authors":["Corey Pittman","Pamela Wisniewski","Conner Brooks","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1462492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1462492800,"objectID":"355c460a8bada6d2269877b4c6889564","permalink":"https://crpittman.github.io/publication/multiwave-ea/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/multiwave-ea/","section":"publication","summary":"We present the results of a user study of Multiwave to evaluate recognition rates for different gestures and report accuracy rates comparable to or better than the current state of the art.","tags":["Gesture Recognition","Novel User Interfaces"],"title":"Multiwave: Doppler Effect Based Gesture Recognition in Multiple Dimensions","type":"publication"},{"authors":["Joseph J. LaViola, Jr.","Sarah Buchanan","Corey Pittman"],"categories":null,"content":"","date":1412553600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1412553600,"objectID":"882081e61e04b15a854302bc920767a5","permalink":"https://crpittman.github.io/publication/multimodal-chapter/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/multimodal-chapter/","section":"publication","summary":"The use of multiple modes of user input to interact with computers and devices is an active area of human computer interaction research. With the advent of more powerful perceptual computing technologies, multimodal interfaces that can passively sense what the user is doing are becoming more prominent. In this chapter, we examine how different natural user input modalities – specifically, speech, gesture, touch, eye gaze, facial expressions, and brain input – can be combined, and the types of interactions they afford. We also examine the strategies for combining these input modes together, otherwise known as multimodal integration or fusion. Finally, we examine some usability issues with multimodal interfaces and methods for handling them.","tags":["Gesture Interaction"],"title":"Multimodal Input for Perceptual User Interfaces","type":"publication"},{"authors":["Corey Pittman","Joseph J. LaViola, Jr."],"categories":null,"content":"","date":1391644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391644800,"objectID":"a78ff88d9929972530f904c673059aee","permalink":"https://crpittman.github.io/publication/drone-hmd/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/drone-hmd/","section":"publication","summary":"We explore the capabilities of head tracking combined with head mounted displays (HMD) as an input modality for robot navigation.","tags":["Human Robot Interaction","Gesture Interaction"],"title":"Exploring Head Tracked Head Mounted Displays for First Person Robot Teleoperation","type":"publication"},{"authors":["Corey Pittman","Eugene M. Taranta II","Joseph J. LaViola Jr."],"categories":null,"content":"","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"7d157e00927e2f804af2b0f44ee96daa","permalink":"https://crpittman.github.io/publication/prototype-selection/","publishdate":"2016-03-06T00:00:00Z","relpermalink":"/publication/prototype-selection/","section":"publication","summary":"We explore the benefits of intelligent prototype selection for $-family recognizers.","tags":["Gesture Recognition"],"title":"A $-Family Friendly Approach to Prototype Selection","type":"publication"}]